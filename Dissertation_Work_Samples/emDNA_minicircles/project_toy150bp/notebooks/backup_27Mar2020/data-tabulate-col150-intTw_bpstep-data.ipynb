{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Objective:\n",
    "Generate a file that gives base-pair step data for each optimized structure\n",
    "Header:\n",
    "bp, dimer, tetramer, tilt, roll, bend, twist, energy, dcenter, anglecenter, Wmaj, Wmin, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, shutil, subprocess, matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import spatial\n",
    "\n",
    "path     = os.getcwd()\n",
    "pathrf   = path+'/opt_refframe'\n",
    "pathpdb  = path+'/opt_pdb'\n",
    "pathpar  = path+'/opt_par'\n",
    "pathbps  = path+'/opt_det-seqs'\n",
    "pathbpp  = path+'/opt_det-pars'\n",
    "pathbfr  = path+'/opt_beta-factors'\n",
    "#pathff   = \"/home/rty10/Documents/Experiments/Optimizations/Opt_ForceFields\"\n",
    "pathff   = \"C:\\\\Users\\\\Young_Research\\\\Documents\\\\Rutgers\\\\Research\\\\Opt_Forcefields\"\n",
    "# --------------------------------------------------------------------------------\n",
    "pathinrf  = path+'/initial_conditions/in_refframe'\n",
    "pathinpdb = path+'/initial_conditions/in_pdb'\n",
    "pathinpar = path+'/initial_conditions/in_par'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dna_data(refframe_file, pdb_file):\n",
    "    \"\"\"\n",
    "    Function that will read both a reference frame file and a file of phosphate atoms from a pdb file.\n",
    "    Goal will be to return a pandas DataFrame with information such as:\n",
    "    - base-pair origin\n",
    "    - base-pair's direction of its minor groove\n",
    "    - the phosphate positions on both its coding (Pi) and complementary (pi) strands\n",
    "    \"\"\"\n",
    "    infile1   = open(refframe_file, 'r')\n",
    "    infile2   = open(pdb_file, 'r')\n",
    "    rfdata    = infile1.readlines()\n",
    "    PDBdata   = infile2.readlines()\n",
    "    infile1.close()\n",
    "    infile2.close()\n",
    "    \n",
    "    df = pd.DataFrame(columns=[\"Ox\",\"Oy\",\"Oz\",\n",
    "                               \"Dx\",\"Dy\",\"Dz\",\n",
    "                               \"-d1x\",\"-d1y\",\"-d1z\",\n",
    "                               \"Dcenter\",\"theta\",\n",
    "                               \"px\",\"py\",\"pz\",\"qx\",\"qy\",\"qz\"])    \n",
    "\n",
    "    Ncirc = int(rfdata[0].split()[0])\n",
    "    rfdata  = [i.split() for i in rfdata]\n",
    "    Odata = []\n",
    "    Xdata = []\n",
    "    for i in range(0, Ncirc):\n",
    "        Odata.append(rfdata[(5*i)+2])\n",
    "        Xdata.append([rfdata[(5*i)+3][0],\n",
    "                      rfdata[(5*i)+4][0],\n",
    "                      rfdata[(5*i)+5][0]])\n",
    "    \n",
    "    for i in range(0, len(Odata)):\n",
    "        df.loc[i, [\"Ox\",\"Oy\",\"Oz\"]]     = float(Odata[i][0]), float(Odata[i][1]), float(Odata[i][2])\n",
    "        df.loc[i, [\"-d1x\",\"-d1y\",\"-d1z\"]] = -1*float(Xdata[i][0]), -1*float(Xdata[i][1]), -1*float(Xdata[i][2])\n",
    "    \n",
    "    com = np.array([float((df['Ox'].sum())/Ncirc),\n",
    "                    float((df['Oy'].sum())/Ncirc),\n",
    "                    float((df['Oz'].sum())/Ncirc)])\n",
    "    for i in range(0, len(Odata)):\n",
    "        orn = np.array(df.loc[i, [\"Ox\",\"Oy\",\"Oz\"]])\n",
    "        ocr = np.array(df.loc[i, [\"-d1x\",\"-d1y\",\"-d1z\"]])\n",
    "        \n",
    "        df.loc[i, [\"Dx\",\"Dy\",\"Dz\"]] = com - orn\n",
    "        df.loc[i, \"Dcenter\"]        = sp.spatial.distance.euclidean(com, orn)\n",
    "        dc = (com - orn)/sp.spatial.distance.euclidean(com, orn)\n",
    "        \n",
    "        df.loc[i, \"theta\"] = np.degrees( np.arccos( np.dot(dc, ocr) ) )\n",
    "        \n",
    "    Pdata = []\n",
    "    for i in range(0, len(PDBdata)):\n",
    "        if \" P \" in PDBdata[i]:\n",
    "            Pdata.append(PDBdata[i])\n",
    "    Pdata = [[i[30:38],i[38:46],i[46:54]] for i in Pdata]\n",
    "    # if this opt as a circle, 1 and Ncirc+1 will be identical    \n",
    "    if len(Pdata) == 2*Ncirc + 2:\n",
    "        for i in range(0, len(Odata)):\n",
    "            df.loc[i, [\"px\",\"py\",\"pz\"]] = float(Pdata[i][0]), float(Pdata[i][1]), float(Pdata[i][2])\n",
    "            j = ((2*Ncirc + 2)-i)-1\n",
    "            df.loc[i, [\"qx\",\"qy\",\"qz\"]] = float(Pdata[j][0]), float(Pdata[j][1]), float(Pdata[j][2])\n",
    "    elif len(Pdata) == 2*Ncirc:\n",
    "        for i in range(0, len(Odata)):\n",
    "            df.loc[i, [\"px\",\"py\",\"pz\"]] = float(Pdata[i][0]), float(Pdata[i][1]), float(Pdata[i][2])\n",
    "            j = ((2*Ncirc)-i)-1\n",
    "            df.loc[i, [\"qx\",\"qy\",\"qz\"]] = float(Pdata[j][0]), float(Pdata[j][1]), float(Pdata[j][2])\n",
    "    del rfdata, PDBdata, Odata, Xdata, Pdata\n",
    "    #df = circ_minor_groove(df)\n",
    "    #df = circ_major_groove(df)\n",
    "    return df, com\n",
    "\n",
    "\n",
    "def load_opt_par_dataframe(filepath, Nseq):\n",
    "    infile = open(filepath, 'r')\n",
    "    indata = infile.readlines()\n",
    "    infile.close()\n",
    "    indata = [i.rstrip('\\n').split() for i in indata]\n",
    "    header = ['basepair',\n",
    "    'Shear','Stretch','Stagger','Buckle','Prop-Tw','Opening',\n",
    "    'Shift','Slide','Rise','Tilt','Roll','Twist']\n",
    "    indata = indata[3:]\n",
    "    for i in range(0, len(indata)):\n",
    "        for j, x in enumerate(indata[i]):\n",
    "            try:\n",
    "                indata[i][j] = float(x)\n",
    "            except ValueError:\n",
    "                pass\n",
    "    df = pd.DataFrame.from_records(indata, columns=header)\n",
    "    del indata\n",
    "    return df\n",
    "\n",
    "\n",
    "def circ_minor_groove(dataframe):\n",
    "    \"\"\"\n",
    "    To calculate the width of the minor groove for a circular structure.\n",
    "    For step 'k', get the average of distances between a pair of phosphates offset by m=-3.\n",
    "    A: distance from coding p(k+1) to complementary q(k-2)\n",
    "    B: distance from coding p(k+2) to complementary q(k-1)\n",
    "    *** For this function, the p phosphates will be complementary to the k-1th step's bp number\n",
    "    *** for k=10 and circular N=150, p((k+1)+2)=p(k+3)=p([13])\n",
    "    \"\"\"\n",
    "    Nseq = len(dataframe)\n",
    "    for k in range(0, Nseq):\n",
    "        if k == 0:\n",
    "            Pk1 = np.array([dataframe.loc[2,      [\"px\",\"py\",\"pz\"]]])\n",
    "            Pk2 = np.array([dataframe.loc[3,      [\"px\",\"py\",\"pz\"]]])\n",
    "            pk1 = np.array([dataframe.loc[Nseq-1, [\"qx\",\"qy\",\"qz\"]]])\n",
    "            pk2 = np.array([dataframe.loc[Nseq-2, [\"qx\",\"qy\",\"qz\"]]])\n",
    "        elif k == 1:\n",
    "            Pk1 = np.array([dataframe.loc[3,      [\"px\",\"py\",\"pz\"]]])\n",
    "            Pk2 = np.array([dataframe.loc[4,      [\"px\",\"py\",\"pz\"]]])\n",
    "            pk1 = np.array([dataframe.loc[0,      [\"qx\",\"qy\",\"qz\"]]])\n",
    "            pk2 = np.array([dataframe.loc[Nseq-1, [\"qx\",\"qy\",\"qz\"]]])\n",
    "        elif k == Nseq-3:\n",
    "            Pk1 = np.array([dataframe.loc[k+2,    [\"px\",\"py\",\"pz\"]]])\n",
    "            Pk2 = np.array([dataframe.loc[0,      [\"px\",\"py\",\"pz\"]]])\n",
    "            pk1 = np.array([dataframe.loc[k-1,    [\"qx\",\"qy\",\"qz\"]]])\n",
    "            pk2 = np.array([dataframe.loc[k-2,    [\"qx\",\"qy\",\"qz\"]]])\n",
    "        elif k == Nseq-2:\n",
    "            Pk1 = np.array([dataframe.loc[0,      [\"px\",\"py\",\"pz\"]]])\n",
    "            Pk2 = np.array([dataframe.loc[1,      [\"px\",\"py\",\"pz\"]]])\n",
    "            pk1 = np.array([dataframe.loc[k-1,    [\"qx\",\"qy\",\"qz\"]]])\n",
    "            pk2 = np.array([dataframe.loc[k-2,    [\"qx\",\"qy\",\"qz\"]]])\n",
    "        elif k == Nseq-1:\n",
    "            Pk1 = np.array([dataframe.loc[1,      [\"px\",\"py\",\"pz\"]]])\n",
    "            Pk2 = np.array([dataframe.loc[2,      [\"px\",\"py\",\"pz\"]]])\n",
    "            pk1 = np.array([dataframe.loc[k-1,    [\"qx\",\"qy\",\"qz\"]]])\n",
    "            pk2 = np.array([dataframe.loc[k-2,    [\"qx\",\"qy\",\"qz\"]]])\n",
    "        else:\n",
    "            Pk1 = np.array([dataframe.loc[k+2,    [\"px\",\"py\",\"pz\"]]])\n",
    "            Pk2 = np.array([dataframe.loc[k+3,    [\"px\",\"py\",\"pz\"]]])\n",
    "            pk1 = np.array([dataframe.loc[k-1,    [\"qx\",\"qy\",\"qz\"]]])\n",
    "            pk2 = np.array([dataframe.loc[k-2,    [\"qx\",\"qy\",\"qz\"]]])\n",
    "        \n",
    "        A = sp.spatial.distance.euclidean(Pk1, pk2)\n",
    "        B = sp.spatial.distance.euclidean(Pk2, pk1)\n",
    "        mg = (1/2)*( A + B )\n",
    "        dataframe.loc[k, \"W-min\"] = mg\n",
    "    del Nseq\n",
    "    return dataframe\n",
    "\n",
    "def circ_major_groove(dataframe):\n",
    "    \"\"\"\n",
    "    To calculate the width of the major groove for a circular structure.\n",
    "    For step 'k', get the average of distances between a pair of phosphates offset by m=4.\n",
    "    mg = distance from coding p((k+1)-2)=p(k-1) to complementary q(k+2)\n",
    "    \"\"\"\n",
    "    Nseq = len(dataframe)\n",
    "    for k in range(0, Nseq):\n",
    "        if k == 0:\n",
    "            Pk2 = np.array([dataframe.loc[Nseq-1, [\"px\",\"py\",\"pz\"]]])\n",
    "            pk2 = np.array([dataframe.loc[2,      [\"qx\",\"qy\",\"qz\"]]])\n",
    "        elif k == 1:\n",
    "            Pk2 = np.array([dataframe.loc[0,      [\"px\",\"py\",\"pz\"]]])\n",
    "            pk2 = np.array([dataframe.loc[3,      [\"qx\",\"qy\",\"qz\"]]])\n",
    "        elif k == Nseq-2:\n",
    "            Pk2 = np.array([dataframe.loc[k-1,    [\"px\",\"py\",\"pz\"]]])\n",
    "            pk2 = np.array([dataframe.loc[0,      [\"qx\",\"qy\",\"qz\"]]])\n",
    "        elif k == Nseq-1:\n",
    "            Pk2 = np.array([dataframe.loc[k-1,    [\"px\",\"py\",\"pz\"]]])\n",
    "            pk2 = np.array([dataframe.loc[1,      [\"qx\",\"qy\",\"qz\"]]])\n",
    "        else:\n",
    "            Pk2 = np.array([dataframe.loc[k-1,    [\"px\",\"py\",\"pz\"]]])\n",
    "            pk2 = np.array([dataframe.loc[k+2,    [\"qx\",\"qy\",\"qz\"]]])\n",
    "            \n",
    "        mg = sp.spatial.distance.euclidean(Pk2, pk2)\n",
    "        dataframe.loc[k, \"W-maj\"] = mg\n",
    "    del Nseq\n",
    "    return dataframe\n",
    "\n",
    "def load_forcefield(ffpath, forcefield):\n",
    "    \"\"\"\n",
    "    Function to generate a dataframe with rest state values from an optimization forcefield\n",
    "    and another dataframe with elastic force constants of the same forcefield\n",
    "    \"\"\"\n",
    "    for filename in os.listdir(ffpath+'/RestStateParameters'):\n",
    "        if forcefield in filename:\n",
    "            infile1 = open(ffpath+'/RestStateParameters/'+filename, 'r')\n",
    "    indata1 = infile1.readlines()\n",
    "    indata1 = [i.replace(\"={\",\" \").replace(\", \",\" \").replace(\"}\",\"\").rstrip('\\n').split() for i in indata1]\n",
    "    for i in range(0, len(indata1)):\n",
    "        for j, x in enumerate(indata1[i]):\n",
    "            try:\tindata1[i][j] = float(x)\n",
    "            except ValueError:\tpass\n",
    "    if forcefield == 'Olson1998' or forcefield == 'olson':\n",
    "        infile2 = open(ffpath+'/ForceConstants/ForceConstants_Olson1998.txt', 'r')\n",
    "    else:\n",
    "        infile2 = open(ffpath+'/ForceConstants/ForceConstants_IdealDNA.txt', 'r')\n",
    "    indata2 = infile2.readlines()\n",
    "    indata2 = [i.replace(\"={\",\" \").replace(\", \",\" \").replace(\"}\",\"\").rstrip('\\n').split() for i in indata2]\n",
    "    for i in range(0, len(indata2)):\n",
    "        for j, x in enumerate(indata2[i]):\n",
    "            try:\tindata2[i][j] = float(x)\n",
    "            except ValueError:\tpass\n",
    "    header1 = ['dimer','tilt','roll','twist','shift','slide','rise']\n",
    "    header2 =['dimer',\n",
    "    'TiltTilt','TiltRoll','TiltTwist','TiltShift','TiltSlide','TiltRise',\n",
    "    'RollTilt','RollRoll','RollTwist','RollShift','RollSlide','RollRise',\n",
    "    'TwistTilt','TwistRoll','TwistTwist','TwistShift','TwistSlide','TwistRise',\n",
    "    'ShiftTilt','ShiftRoll','ShiftTwist','ShiftShift','ShiftSlide','ShiftRise',\n",
    "    'SlideTilt','SlideRoll','SlideTwist','SlideShift','SlideSlide','SlideRise',\n",
    "    'RiseTilt','RiseRoll','RiseTwist','RiseShift','RiseSlide','RiseRise']\n",
    "    df1 = pd.DataFrame.from_records(indata1, columns=header1)\n",
    "    df2 = pd.DataFrame.from_records(indata2, columns=header2)\n",
    "    indata2 = infile2.readlines()\n",
    "    del indata1, indata2\n",
    "    return df1, df2\n",
    "\n",
    "def insert_bpstep_seq_circular(opt_par_dataframe):\n",
    "    \"\"\"\n",
    "    From a dataframe with a column of base-pairs, generate the dimer and tetramer for each bp.\n",
    "    Add new dimer and tetramer columns to dataframe.\n",
    "    Note: this is for circular constructions\n",
    "    \"\"\"\n",
    "    bpseq  = opt_par_dataframe['basepair']\n",
    "    for k in range(0, len(bpseq)):\n",
    "        first, second, third, fourth = k-2, k-1, k, k+1 \n",
    "        if k-2 == -2:\n",
    "            first  = (Nseq - 2)\n",
    "            second = (Nseq - 1)\n",
    "        elif k-2 == -1:\n",
    "            first = (Nseq - 1)\n",
    "        elif k == Nseq-1:\n",
    "            fourth = 0\n",
    "        elif k == Nseq:\n",
    "            second = (Nseq-1)\n",
    "            third  = 0\n",
    "            fourth = 1\n",
    "        a = bpseq[first].split('-')[0]\n",
    "        b = bpseq[second].split('-')[0]\n",
    "        c = bpseq[third].split('-')[0]\n",
    "        d = bpseq[fourth].split('-')[0]\n",
    "        dimerstep = \"\".join((b, c))\n",
    "        tetrastep = \"\".join((a, b, c, d))\n",
    "        opt_par_dataframe.at[k, 'dimer'] = dimerstep\n",
    "        opt_par_dataframe.at[k, 'tetramer'] = tetrastep\n",
    "    return opt_par_dataframe\n",
    "\n",
    "def insert_bps_bend(opt_par_dataframe):\n",
    "    \"\"\"\n",
    "    Function that takes the tilt and roll columns from a loaded dataframe and determines the bend angle.\n",
    "    \"\"\"\n",
    "    for k in range(0, len(opt_par_dataframe)):\n",
    "        x = float(opt_par_dataframe.loc[k, 'Tilt'])\n",
    "        y = float(opt_par_dataframe.loc[k, 'Roll'])\n",
    "        opt_par_dataframe.loc[k, 'Bend'] = float(np.sqrt(x**2 + y**2))\n",
    "    return opt_par_dataframe\n",
    "\n",
    "def insert_bps_energy(Nseq, opt_par_dataframe, reststate_par_dataframe, elastic_constants_dataframe):\n",
    "    \"\"\"\n",
    "    Function that determines the energy per base-pair step.\n",
    "    Must have:\n",
    "    - loaded rest state dataframe\n",
    "    - loaded elastic force constant dataframe\n",
    "    - column with dimer and/or tetramer steps\n",
    "    \"\"\"\n",
    "    opt_par_dataframe.loc[0, 'Energy'] = float(0)\n",
    "    for k in range(1, len(opt_par_dataframe)):\n",
    "        dim = opt_par_dataframe.loc[k, 'dimer']\n",
    "        oshift, oslide, orise, otilt, oroll, otwist = [j for j in opt_par_dataframe.loc[k, 'Shift':'Twist']]\n",
    "        A = np.array([otilt, oroll, otwist, oshift, oslide, orise])\n",
    "        for j in range(0, len(reststate_par_dataframe)):\n",
    "            if reststate_par_dataframe.loc[j, 'dimer'] == dim:\n",
    "                B = np.array([z for z in reststate_par_dataframe.loc[j, 'tilt':'rise']])\n",
    "        for j in range(0, len(elastic_constants_dataframe)):\n",
    "            if elastic_constants_dataframe.loc[j, 'dimer'] == dim:\n",
    "                F = np.array([[z for z in elastic_constants_dataframe.loc[j, 'TiltTilt':'TiltRise']],\n",
    "                              [z for z in elastic_constants_dataframe.loc[j, 'RollTilt':'RollRise']],\n",
    "                              [z for z in elastic_constants_dataframe.loc[j, 'TwistTilt':'TwistRise']],\n",
    "                              [z for z in elastic_constants_dataframe.loc[j, 'ShiftTilt':'ShiftRise']],\n",
    "                              [z for z in elastic_constants_dataframe.loc[j, 'SlideTilt':'SlideRise']],\n",
    "                              [z for z in elastic_constants_dataframe.loc[j, 'RiseTilt':'RiseRise']]])\n",
    "        opt_par_dataframe.loc[k, 'Energy'] = (1/2)*np.trace( (A-B) * F * (A-B) )\n",
    "    return opt_par_dataframe\n",
    "\n",
    "\n",
    "# --- Output new parameter file ---\n",
    "def newfile_bpsdata(Nseq, main_dataframe, outputfilepath, outputname):\n",
    "    \"\"\"\n",
    "    bp, dimer, tetramer, tilt, roll, bend, twist, energy, dcenter, anglecenter, Wmaj, Wmin, ...\n",
    "    \"\"\"\n",
    "    A = main_dataframe\n",
    "    outfile = open(outputfilepath+'/'+outputname+'_bps-data.txt', 'w')\n",
    "    outfile.write(str(Nseq)+'  # base pairs\\n')\n",
    "    if not \"initial\" in str(outputfilepath):\n",
    "        outfile.write(\"{:<4}{:>6}{:>9}{:>10}{:>10}{:>10}{:>10}{:>10}{:>10}{:>10}{:>10}{:>10}\\n\".format(\n",
    "        'bp','dimer','tetramer','Tilt','Roll','Bend','Twist','Energy','Dcenter','theta','W-maj','W-min'\n",
    "        ))\n",
    "        for i in range(0, len(A)):\n",
    "            outfile.write(\"{:<4}{:>6}{:>9}{:>10}{:>10}{:>10}{:>10}{:>10}{:>10}{:>10}{:>10}{:>10}\\n\".format(\n",
    "            A.loc[i, 'basepair'], A.loc[i, 'dimer'], A.loc[i, 'tetramer'],\n",
    "            round(A.loc[i, 'Tilt'],5),round(A.loc[i, 'Roll'],5),round(A.loc[i, 'Bend'],5),round(A.loc[i, 'Twist'],5),round(A.loc[i, 'Energy'], 5),\n",
    "            round(A.loc[i, 'Dcenter'], 5), round(A.loc[i, 'theta'], 5), round(A.loc[i, 'W-maj'], 5), round(A.loc[i, 'W-min'], 5) \n",
    "            ))\n",
    "        outfile.close()\n",
    "    else:\n",
    "        outfile.write(\"{:<4}{:>6}{:>9}{:>10}{:>10}{:>10}{:>10}{:>10}{:>10}{:>10}{:>10}\\n\".format(\n",
    "        'bp','dimer','tetramer','Tilt','Roll','Bend','Twist','Dcenter','theta','W-maj','W-min'\n",
    "        ))\n",
    "        for i in range(0, len(A)):\n",
    "            outfile.write(\"{:<4}{:>6}{:>9}{:>10}{:>10}{:>10}{:>10}{:>10}{:>10}{:>10}{:>10}\\n\".format(\n",
    "            A.loc[i, 'basepair'], A.loc[i, 'dimer'], A.loc[i, 'tetramer'],\n",
    "            round(A.loc[i, 'Tilt'],5),round(A.loc[i, 'Roll'],5),round(A.loc[i, 'Bend'],5),round(A.loc[i, 'Twist'],5),\n",
    "            round(A.loc[i, 'Dcenter'], 5), round(A.loc[i, 'theta'], 5), round(A.loc[i, 'W-maj'], 5), round(A.loc[i, 'W-min'], 5) \n",
    "            ))\n",
    "        outfile.close()\n",
    "    return\n",
    "\n",
    "def load_optdetailed_df(filepath):\n",
    "    infile = open(filepath, 'r')\n",
    "    indata = infile.readlines()\n",
    "    infile.close()\n",
    "    indata = [i.rstrip('\\n').split() for i in indata]\n",
    "    for i in range(0, len(indata)):\n",
    "        for j, x in enumerate(indata[i]):\n",
    "            try:\n",
    "                indata[i][j] = float(x)\n",
    "            except ValueError:\n",
    "                pass\n",
    "    df = pd.DataFrame.from_records(indata[2:], columns=indata[1:2])\n",
    "    df.index = [i for i in range(1, len(df)+1)]\n",
    "    del indata\n",
    "    return df\n",
    "\n",
    "def df_reststate(path):\n",
    "    infile1 = open(path, 'r')\n",
    "    indata1 = infile1.readlines()\n",
    "    infile1.close()            \n",
    "    indata1 = [i.replace(\"={\",\" \").replace(\", \",\" \").replace(\"}\",\"\").rstrip('\\n').split() for i in indata1]\n",
    "    rsdf = pd.DataFrame.from_records(indata1, columns=['dimer','Tilt','Roll','Twist','shift','slide','rise'])\n",
    "    rsdf = rsdf.astype({'Tilt':\"float64\",'Roll':\"float64\",'Twist':\"float64\",'shift':\"float64\",'slide':\"float64\",'rise':\"float64\"})\n",
    "    rsdf = rsdf.set_index('dimer')\n",
    "    return rsdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate detailed base-pair step files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "for filename in os.listdir(pathrf):\n",
    "    lst.append(filename.split('.')[0])\n",
    "lst = sorted(lst)\n",
    "\n",
    "Nseq = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in lst:\n",
    "\n",
    "    df1, Dcenter = dna_data(pathrf+'/'+filename+'.dat', pathpdb+'/'+filename+'.pdb')\n",
    "    df2 = load_opt_par_dataframe(pathpar+'/'+filename+'.par', Nseq)\n",
    "    dfrs, dffc = load_forcefield(pathff, filename.split('_')[3])\n",
    "\n",
    "    df1 = circ_major_groove(df1)\n",
    "    df1 = circ_minor_groove(df1)\n",
    "\n",
    "    df2 = insert_bpstep_seq_circular(df2)\n",
    "    df2 = insert_bps_bend(df2)\n",
    "    df2 = insert_bps_energy(Nseq, df2, dfrs, dffc)\n",
    "\n",
    "    df3 = df1[['Dcenter','theta','W-maj','W-min']]\n",
    "    df3 = pd.concat([df3, df2[['basepair','dimer','tetramer','Tilt','Roll','Bend','Twist','Energy']]], axis=1)\n",
    "    df3 = df3[['basepair','dimer','tetramer','Tilt','Roll','Bend','Twist','Energy','Dcenter','theta','W-maj','W-min']]\n",
    "    del df1, df2, dfrs, dffc\n",
    "\n",
    "    newfile_bpsdata(Nseq, df3, path+'/opt_det-seqs', filename)\n",
    "    \n",
    "    del df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate forcefield-specific parameter files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "for filename in os.listdir(pathbps):\n",
    "    lst.append(filename.split('.')[0])\n",
    "lst = sorted(lst)\n",
    "\n",
    "Nseq      = 150\n",
    "inseqs    = ['col'+str(i).zfill(2) for i in range(1, 10)]\n",
    "ff_states = ['1st','2st','3st','4st']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([ff_states[0]+\"-\"+str(i).zfill(3) for i in range(90, 111, 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERATE .csv FILES OF DATA\n",
    "# -!- Twist, Bend, and Roll parameters\n",
    "for seq in inseqs:\n",
    "    for Incon in [\"pcirc\", \"oring\"]:\n",
    "        for Par in ['Roll','Twist','Bend']:\n",
    "            for Forcefield in ['1st','2st','3st','4st']:\n",
    "                ideal_df = pd.read_csv('C:/Users/Young_Research/Documents/Rutgers/Research/2019_PHY_MSc/seq_Coleman150/col150-i-standard-circles/opt_det-seqs/col01_'+Incon+'_std_ideal_bps-data.txt', delimiter= '\\s+',skiprows=0,header=1)\n",
    "                df = pd.DataFrame(ideal_df[Par]).rename(columns={Par:\"ideal\"})     \n",
    "                for l in lst:\n",
    "                    if seq in l and Forcefield in l and Incon in l:\n",
    "                        #name = l.split('_')[0]\n",
    "                        rsdf = df_reststate(pathff+'/RestStateParameters/StepParameters_'+l.split('_')[3]+'.txt')\n",
    "                        df1 = pd.read_csv(pathbps+'/'+l+'.txt', delimiter= '\\s+', skiprows=0, header=1)\n",
    "                        \n",
    "                        if 'seq' not in df:\n",
    "                            df[\"seq\"]    = pd.Series(df1['dimer'], index=df.index)\n",
    "                        \n",
    "                        if Par == 'Bend':\n",
    "                            for x in range(0, len(df)):\n",
    "                                df.at[x, 'rs_'+l.split('_')[3]] = abs(rsdf.at[df.at[x, 'seq'], 'Roll'])\n",
    "                        else:\n",
    "                            for x in range(0, len(df)):\n",
    "                                df.at[x, 'rs_'+l.split('_')[3]] = rsdf.at[df.at[x, 'seq'], Par]\n",
    "\n",
    "                        df[\"opt_\"+l.split('_')[3]]    = pd.Series(df1[Par], index=df.index)\n",
    "                        df['delta_'+l.split('_')[3]]  = df[\"opt_\"+l.split('_')[3]]-df[\"rs_\"+l.split('_')[3]]\n",
    "                        df['delta*_'+l.split('_')[3]] = df[\"opt_\"+l.split('_')[3]]-df.ideal\n",
    "                        del df1\n",
    "\n",
    "                df = df[1:]\n",
    "                cols   = ['ideal']+[\"seq\"]+[\"rs_\"+Forcefield+\"-\"+str(i).zfill(3) for i in range(90, 111, 1)]+['opt_'+Forcefield+\"-\"+str(i).zfill(3) for i in range(90, 111, 1)]+['delta_'+Forcefield+\"-\"+str(i).zfill(3) for i in range(90, 111, 1)]+['delta*_'+Forcefield+\"-\"+str(i).zfill(3) for i in range(90, 111, 1)]\n",
    "                df = df.reindex(cols, axis=1)\n",
    "                df.to_csv(seq+\"_\"+Incon+\"_\"+Forcefield+\"_\"+Par+\"_std\")\n",
    "                del ideal_df, df, cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERATE .csv FILES OF DATA\n",
    "# -!- Energy\n",
    "for seq in inseqs:\n",
    "    for Incon in [\"pcirc\", \"oring\"]:\n",
    "        for Par in ['Energy']:\n",
    "            for Forcefield in ['1st','2st','3st','4st']:\n",
    "                ideal_df = pd.read_csv('C:/Users/Young_Research/Documents/Rutgers/Research/2019_PHY_MSc/seq_Coleman150/col150-i-standard-circles/opt_det-seqs/col01_'+Incon+'_std_ideal_bps-data.txt', delimiter= '\\s+',skiprows=0,header=1)\n",
    "                df = pd.DataFrame(ideal_df[Par]).rename(columns={Par:\"ideal\"})     \n",
    "                for l in lst:\n",
    "                    if seq in l and Forcefield in l and Incon in l:\n",
    "                        #name = l.split('_')[0]\n",
    "                        rsdf = df_reststate(pathff+'/RestStateParameters/StepParameters_'+l.split('_')[3]+'.txt')\n",
    "                        df1 = pd.read_csv(pathbps+'/'+l+'.txt', delimiter= '\\s+', skiprows=0, header=1)\n",
    "                        if 'seq' not in df:\n",
    "                            df[\"seq\"]    = pd.Series(df1['dimer'], index=df.index)\n",
    "                        df[\"opt_\"+l.split('_')[3]]    = pd.Series(df1[Par], index=df.index)\n",
    "                        df['delta*_'+l.split('_')[3]] = df[\"opt_\"+l.split('_')[3]]-df.ideal\n",
    "                        del df1\n",
    "\n",
    "                df = df[1:]\n",
    "                cols   = ['ideal']+[\"seq\"]+['opt_'+Forcefield+\"-\"+str(i).zfill(3) for i in range(90, 111, 1)]+['delta_'+Forcefield+\"-\"+str(i).zfill(3) for i in range(90, 111, 1)]+['delta*_'+Forcefield+\"-\"+str(i).zfill(3) for i in range(90, 111, 1)]\n",
    "                df = df.reindex(cols, axis=1)\n",
    "                df.to_csv(seq+\"_\"+Incon+\"_\"+Forcefield+\"_\"+Par+\"_std\")\n",
    "                del ideal_df, df, cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"col08_pcirc_3st_Energy_std\", index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERATE .csv FILES OF DATA\n",
    "# -!- Dcenter, W-min, and theta values\n",
    "for seq in inseqs:\n",
    "    for Incon in [\"pcirc\", \"oring\"]:\n",
    "        for Par in ['W-min','Dcenter','theta']:\n",
    "            for Forcefield in ['1st','2st','3st','4st']:\n",
    "                ideal_df = pd.read_csv('C:/Users/Young_Research/Documents/Rutgers/Research/2019_PHY_MSc/seq_Coleman150/col150-i-standard-circles/opt_det-seqs/col01_'+Incon+'_std_ideal_bps-data.txt', delimiter= '\\s+',skiprows=0,header=1)\n",
    "                df = pd.DataFrame(ideal_df[Par]).rename(columns={Par:\"ideal\"})     \n",
    "                for l in lst:\n",
    "                    if seq in l and Forcefield in l and Incon in l:\n",
    "                        #name = l.split('_')[0]\n",
    "                        rsdf = df_reststate(pathff+'/RestStateParameters/StepParameters_'+l.split('_')[3]+'.txt')\n",
    "                        df1 = pd.read_csv(pathbps+'/'+l+'.txt', delimiter= '\\s+', skiprows=0, header=1)\n",
    "                        if 'seq' not in df:\n",
    "                            df[\"seq\"]    = pd.Series(df1['dimer'], index=df.index)\n",
    "                        df[\"opt_\"+l.split('_')[3]]    = pd.Series(df1[Par], index=df.index)\n",
    "                        df['delta*_'+l.split('_')[3]] = df[\"opt_\"+l.split('_')[3]]-df.ideal\n",
    "                        del df1\n",
    "\n",
    "                df = df[1:]\n",
    "                cols   = ['ideal']+[\"seq\"]+['opt_'+Forcefield+\"-\"+str(i).zfill(3) for i in range(90, 111, 1)]+['delta_'+Forcefield+\"-\"+str(i).zfill(3) for i in range(90, 111, 1)]+['delta*_'+Forcefield+\"-\"+str(i).zfill(3) for i in range(90, 111, 1)]\n",
    "                df = df.reindex(cols, axis=1)\n",
    "                df.to_csv(seq+\"_\"+Incon+\"_\"+Forcefield+\"_\"+Par+\"_std\")\n",
    "                del ideal_df, df, cols\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beta Factor Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Need to make beta factor files for norm twist and difference twist for each sequence\n",
    "datatypes = ['Bend','Dcenter','Energy','Roll','Twist','W-min']\n",
    "datalabs  = {'Bend':'bend', 'Dcenter':'radius', 'Energy':'energy',\n",
    "            'Roll':'roll',  'Twist':'twist',    'W-min':'wmin'}\n",
    "\n",
    "for x in range(0, len(datatypes)):\n",
    "    for y in ['norm','excess','diff']:\n",
    "        A = pathbfr+'/'+datalabs[datatypes[x]]+'_'+y\n",
    "        if not os.path.exists(A):\n",
    "            os.mkdir(A)\n",
    "        del A\n",
    "\n",
    "for x in range(0, len(datatypes)):\n",
    "    for Incon in ['pcirc','oring']:\n",
    "        for y in inseqs:\n",
    "            for f in range(0, len(ff_states)):\n",
    "                forcefields = [ff_states[f]+'-'+str(i).zfill(3) for i in range(90, 111, 1)]\n",
    "                for i in range(0, len(forcefields)):\n",
    "                    df = pd.read_csv(pathbpp+'/'+seq+'_'+Incon+'_'+ff_states[f]+'_'+datatypes[x]+'_std', index_col=0)\n",
    "                    name = y+'_'+Incon+'_std_'+forcefields[i]\n",
    "\n",
    "                    #Excess data\n",
    "                    if datatypes[x] == 'Roll' or datatypes[x] == 'Twist' or datatypes[x] == 'Bend':\n",
    "                        name2 = name+'_'+datalabs[datatypes[x]]+'-excess'\n",
    "                        slot = df['delta_'+forcefields[i]]\n",
    "                        A = slot.to_list()\n",
    "                        B = A + A[0:1]+A[0:1] + A[::-1]\n",
    "                        B = [ float(b) for b in B]\n",
    "                        B = [ '%.6f' % b for b in B]\n",
    "                        outfile = open(pathbfr+'/'+name2+'.txt','w')\n",
    "                        for k in range(0, len(B)):\n",
    "                            outfile.write(str(round(float(B[k]), 6))+'\\n')\n",
    "                        outfile.close()\n",
    "                        del A, B, name2\n",
    "\n",
    "                    #Difference data\n",
    "                    name2 = name+'_'+datalabs[datatypes[x]]+'-diff'\n",
    "                    slot = df['delta*_'+forcefields[i]]\n",
    "                    A = slot.to_list()\n",
    "                    B = A + A[0:1]+A[0:1] + A[::-1]\n",
    "                    B = [ float(b) for b in B]\n",
    "                    B = [ '%.6f' % b for b in B]\n",
    "                    outfile = open(pathbfr+'/'+name2+'.txt','w')\n",
    "                    for k in range(0, len(B)):\n",
    "                        outfile.write(str(round(float(B[k]), 6))+'\\n')\n",
    "                    outfile.close()\n",
    "                    del A, B, name2\n",
    "\n",
    "                    #Normalization data\n",
    "                    name2 = name+'_'+datalabs[datatypes[x]]+'-norm'\n",
    "                    slot = df['opt_'+forcefields[i]]\n",
    "                    normopt = ( slot-slot.min() )  / ( slot.max() - slot.min() )\n",
    "                    A = normopt.to_list()\n",
    "                    B = A + A[0:1]+A[0:1] + A[::-1]\n",
    "                    B = [ float(b) for b in B]\n",
    "                    B = [ '%.6f' % b for b in B]\n",
    "                    outfile = open(pathbfr+'/'+name2+'.txt','w')\n",
    "                    for k in range(0, len(B)):\n",
    "                        outfile.write(str(round(float(B[k]), 6))+'\\n')\n",
    "                    outfile.close()\n",
    "                    del A, B, name2\n",
    "\n",
    "                    del df, slot\n",
    "\n",
    "\n",
    "for filename in os.listdir(pathbfr):\n",
    "    if filename.endswith('.txt'):\n",
    "        x = filename.split('.')[0].split('_')[4]\n",
    "        X = x.split('-')[0]+'_'+x.split('-')[1]\n",
    "        shutil.move(pathbfr+'/'+filename, pathbfr+'/'+X)\n",
    "        del x, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
