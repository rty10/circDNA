{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, shutil, subprocess, matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.offsetbox import AnchoredText\n",
    "from scipy import spatial\n",
    "\n",
    "path     = os.getcwd()\n",
    "\n",
    "pathrf  = path+'/jul2020/in_refframe'\n",
    "pathpdb = path+'/jul2020/in_pdb'\n",
    "pathpar = path+'/jul2020/in_circ_par'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dna_data(refframe_file, pdb_file):\n",
    "    \"\"\"\n",
    "    Function that will read both a reference frame file and a file of phosphate atoms from a pdb file.\n",
    "    Goal will be to return a pandas DataFrame with information such as:\n",
    "    - base-pair origin\n",
    "    - base-pair's direction of its minor groove\n",
    "    - the phosphate positions on both its coding (Pi) and complementary (pi) strands\n",
    "    \"\"\"\n",
    "    infile1   = open(refframe_file, 'r')\n",
    "    infile2   = open(pdb_file, 'r')\n",
    "    rfdata    = infile1.readlines()\n",
    "    PDBdata   = infile2.readlines()\n",
    "    infile1.close()\n",
    "    infile2.close()\n",
    "    \n",
    "    df = pd.DataFrame(columns=[\"Ox\",\"Oy\",\"Oz\",\n",
    "                               \"Dx\",\"Dy\",\"Dz\",\n",
    "                               \"-d1x\",\"-d1y\",\"-d1z\",\n",
    "                               \"distance\",\"theta\",\n",
    "                               \"px\",\"py\",\"pz\",\"qx\",\"qy\",\"qz\"])    \n",
    "\n",
    "    Ncirc = int(rfdata[0].split()[0])\n",
    "    rfdata  = [i.split() for i in rfdata]\n",
    "    Odata = []\n",
    "    Xdata = []\n",
    "    for i in range(0, Ncirc):\n",
    "        Odata.append(rfdata[(5*i)+2])\n",
    "        Xdata.append([rfdata[(5*i)+3][0],\n",
    "                      rfdata[(5*i)+4][0],\n",
    "                      rfdata[(5*i)+5][0]])\n",
    "    \n",
    "    for i in range(0, len(Odata)):\n",
    "        df.loc[i, [\"Ox\",\"Oy\",\"Oz\"]]     = float(Odata[i][0]), float(Odata[i][1]), float(Odata[i][2])\n",
    "        df.loc[i, [\"-d1x\",\"-d1y\",\"-d1z\"]] = -1*float(Xdata[i][0]), -1*float(Xdata[i][1]), -1*float(Xdata[i][2])\n",
    "    \n",
    "    com = np.array([float((df['Ox'].sum())/Ncirc),\n",
    "                    float((df['Oy'].sum())/Ncirc),\n",
    "                    float((df['Oz'].sum())/Ncirc)])\n",
    "    for i in range(0, len(Odata)):\n",
    "        orn = np.array(df.loc[i, [\"Ox\",\"Oy\",\"Oz\"]])\n",
    "        ocr = np.array(df.loc[i, [\"-d1x\",\"-d1y\",\"-d1z\"]])\n",
    "        \n",
    "        df.loc[i, [\"Dx\",\"Dy\",\"Dz\"]] = com - orn\n",
    "        df.loc[i, \"distance\"]        = sp.spatial.distance.euclidean(com, orn)\n",
    "        dc = (com - orn)/sp.spatial.distance.euclidean(com, orn)\n",
    "        \n",
    "        df.loc[i, \"theta\"] = np.degrees( np.arccos( np.dot(dc, ocr) ) )\n",
    "        \n",
    "    Pdata = []\n",
    "    for i in range(0, len(PDBdata)):\n",
    "        if \" P \" in PDBdata[i]:\n",
    "            Pdata.append(PDBdata[i])\n",
    "    Pdata = [[i[30:38],i[38:46],i[46:54]] for i in Pdata]\n",
    "    # if this opt as a circle, 1 and Ncirc+1 will be identical    \n",
    "    if len(Pdata) == 2*Ncirc + 2:\n",
    "        for i in range(0, len(Odata)):\n",
    "            df.loc[i, [\"px\",\"py\",\"pz\"]] = float(Pdata[i][0]), float(Pdata[i][1]), float(Pdata[i][2])\n",
    "            j = ((2*Ncirc + 2)-i)-1\n",
    "            df.loc[i, [\"qx\",\"qy\",\"qz\"]] = float(Pdata[j][0]), float(Pdata[j][1]), float(Pdata[j][2])\n",
    "    elif len(Pdata) == 2*Ncirc:\n",
    "        for i in range(0, len(Odata)):\n",
    "            df.loc[i, [\"px\",\"py\",\"pz\"]] = float(Pdata[i][0]), float(Pdata[i][1]), float(Pdata[i][2])\n",
    "            j = ((2*Ncirc)-i)-1\n",
    "            df.loc[i, [\"qx\",\"qy\",\"qz\"]] = float(Pdata[j][0]), float(Pdata[j][1]), float(Pdata[j][2])\n",
    "    del rfdata, PDBdata, Odata, Xdata, Pdata\n",
    "    #df = circ_minor_groove(df)\n",
    "    #df = circ_major_groove(df)\n",
    "    return df, com\n",
    "\n",
    "\n",
    "def load_opt_par_dataframe(filepath, Nseq):\n",
    "    infile = open(filepath, 'r')\n",
    "    indata = infile.readlines()\n",
    "    infile.close()\n",
    "    indata = [i.rstrip('\\n').split() for i in indata]\n",
    "    header = ['basepair',\n",
    "    'Shear','Stretch','Stagger','Buckle','Prop-Tw','Opening',\n",
    "    'Shift','Slide','Rise','Tilt','Roll','Twist']\n",
    "    indata = indata[3:]\n",
    "    for i in range(0, len(indata)):\n",
    "        for j, x in enumerate(indata[i]):\n",
    "            try:\n",
    "                indata[i][j] = float(x)\n",
    "            except ValueError:\n",
    "                pass\n",
    "    df = pd.DataFrame.from_records(indata, columns=header)\n",
    "    del indata\n",
    "    return df\n",
    "\n",
    "\n",
    "def circ_minor_groove(dataframe):\n",
    "    \"\"\"\n",
    "    To calculate the width of the minor groove for a circular structure.\n",
    "    For step 'k', get the average of distances between a pair of phosphates offset by m=-3.\n",
    "    A: distance from coding p(k+1) to complementary q(k-2)\n",
    "    B: distance from coding p(k+2) to complementary q(k-1)\n",
    "    *** For this function, the p phosphates will be complementary to the k-1th step's bp number\n",
    "    *** for k=10 and circular N=150, p((k+1)+2)=p(k+3)=p([13])\n",
    "    \"\"\"\n",
    "    Nseq = len(dataframe)\n",
    "    for k in range(0, Nseq):\n",
    "        if k == 0:\n",
    "            Pk1 = np.array([dataframe.loc[2,      [\"px\",\"py\",\"pz\"]]])\n",
    "            Pk2 = np.array([dataframe.loc[3,      [\"px\",\"py\",\"pz\"]]])\n",
    "            pk1 = np.array([dataframe.loc[Nseq-1, [\"qx\",\"qy\",\"qz\"]]])\n",
    "            pk2 = np.array([dataframe.loc[Nseq-2, [\"qx\",\"qy\",\"qz\"]]])\n",
    "        elif k == 1:\n",
    "            Pk1 = np.array([dataframe.loc[3,      [\"px\",\"py\",\"pz\"]]])\n",
    "            Pk2 = np.array([dataframe.loc[4,      [\"px\",\"py\",\"pz\"]]])\n",
    "            pk1 = np.array([dataframe.loc[0,      [\"qx\",\"qy\",\"qz\"]]])\n",
    "            pk2 = np.array([dataframe.loc[Nseq-1, [\"qx\",\"qy\",\"qz\"]]])\n",
    "        elif k == Nseq-3:\n",
    "            Pk1 = np.array([dataframe.loc[k+2,    [\"px\",\"py\",\"pz\"]]])\n",
    "            Pk2 = np.array([dataframe.loc[0,      [\"px\",\"py\",\"pz\"]]])\n",
    "            pk1 = np.array([dataframe.loc[k-1,    [\"qx\",\"qy\",\"qz\"]]])\n",
    "            pk2 = np.array([dataframe.loc[k-2,    [\"qx\",\"qy\",\"qz\"]]])\n",
    "        elif k == Nseq-2:\n",
    "            Pk1 = np.array([dataframe.loc[0,      [\"px\",\"py\",\"pz\"]]])\n",
    "            Pk2 = np.array([dataframe.loc[1,      [\"px\",\"py\",\"pz\"]]])\n",
    "            pk1 = np.array([dataframe.loc[k-1,    [\"qx\",\"qy\",\"qz\"]]])\n",
    "            pk2 = np.array([dataframe.loc[k-2,    [\"qx\",\"qy\",\"qz\"]]])\n",
    "        elif k == Nseq-1:\n",
    "            Pk1 = np.array([dataframe.loc[1,      [\"px\",\"py\",\"pz\"]]])\n",
    "            Pk2 = np.array([dataframe.loc[2,      [\"px\",\"py\",\"pz\"]]])\n",
    "            pk1 = np.array([dataframe.loc[k-1,    [\"qx\",\"qy\",\"qz\"]]])\n",
    "            pk2 = np.array([dataframe.loc[k-2,    [\"qx\",\"qy\",\"qz\"]]])\n",
    "        else:\n",
    "            Pk1 = np.array([dataframe.loc[k+2,    [\"px\",\"py\",\"pz\"]]])\n",
    "            Pk2 = np.array([dataframe.loc[k+3,    [\"px\",\"py\",\"pz\"]]])\n",
    "            pk1 = np.array([dataframe.loc[k-1,    [\"qx\",\"qy\",\"qz\"]]])\n",
    "            pk2 = np.array([dataframe.loc[k-2,    [\"qx\",\"qy\",\"qz\"]]])\n",
    "        \n",
    "        A = sp.spatial.distance.euclidean(Pk1, pk2)\n",
    "        B = sp.spatial.distance.euclidean(Pk2, pk1)\n",
    "        mg = (1/2)*( A + B )\n",
    "        dataframe.loc[k, \"W-min\"] = mg\n",
    "    del Nseq\n",
    "    return dataframe\n",
    "\n",
    "def circ_major_groove(dataframe):\n",
    "    \"\"\"\n",
    "    To calculate the width of the major groove for a circular structure.\n",
    "    For step 'k', get the average of distances between a pair of phosphates offset by m=4.\n",
    "    mg = distance from coding p((k+1)-2)=p(k-1) to complementary q(k+2)\n",
    "    \"\"\"\n",
    "    Nseq = len(dataframe)\n",
    "    for k in range(0, Nseq):\n",
    "        if k == 0:\n",
    "            Pk2 = np.array([dataframe.loc[Nseq-1, [\"px\",\"py\",\"pz\"]]])\n",
    "            pk2 = np.array([dataframe.loc[2,      [\"qx\",\"qy\",\"qz\"]]])\n",
    "        elif k == 1:\n",
    "            Pk2 = np.array([dataframe.loc[0,      [\"px\",\"py\",\"pz\"]]])\n",
    "            pk2 = np.array([dataframe.loc[3,      [\"qx\",\"qy\",\"qz\"]]])\n",
    "        elif k == Nseq-2:\n",
    "            Pk2 = np.array([dataframe.loc[k-1,    [\"px\",\"py\",\"pz\"]]])\n",
    "            pk2 = np.array([dataframe.loc[0,      [\"qx\",\"qy\",\"qz\"]]])\n",
    "        elif k == Nseq-1:\n",
    "            Pk2 = np.array([dataframe.loc[k-1,    [\"px\",\"py\",\"pz\"]]])\n",
    "            pk2 = np.array([dataframe.loc[1,      [\"qx\",\"qy\",\"qz\"]]])\n",
    "        else:\n",
    "            Pk2 = np.array([dataframe.loc[k-1,    [\"px\",\"py\",\"pz\"]]])\n",
    "            pk2 = np.array([dataframe.loc[k+2,    [\"qx\",\"qy\",\"qz\"]]])\n",
    "            \n",
    "        mg = sp.spatial.distance.euclidean(Pk2, pk2)\n",
    "        dataframe.loc[k, \"W-maj\"] = mg\n",
    "    del Nseq\n",
    "    return dataframe\n",
    "\n",
    "def load_forcefield(ffpath, forcefield):\n",
    "    \"\"\"\n",
    "    Function to generate a dataframe with rest state values from an optimization forcefield\n",
    "    and another dataframe with elastic force constants of the same forcefield\n",
    "    \"\"\"\n",
    "    if '-rt' in forcefield:\n",
    "        ff = forcefield.rstrip('-rt')\n",
    "        for filename in os.listdir(ffpath+'/RestStateParameters'):\n",
    "            if ff in filename:\n",
    "                infile1 = open(ffpath+'/RestStateParameters/'+filename, 'r')\n",
    "    else:\n",
    "        for filename in os.listdir(ffpath+'/RestStateParameters'):\n",
    "            if forcefield in filename:\n",
    "                infile1 = open(ffpath+'/RestStateParameters/'+filename, 'r')\n",
    "    indata1 = infile1.readlines()\n",
    "    indata1 = [i.replace(\"={\",\" \").replace(\", \",\" \").replace(\"}\",\"\").rstrip('\\n').split() for i in indata1]\n",
    "    for i in range(0, len(indata1)):\n",
    "        for j, x in enumerate(indata1[i]):\n",
    "            try:\tindata1[i][j] = float(x)\n",
    "            except ValueError:\tpass\n",
    "    \n",
    "    if '-rt' in forcefield:\n",
    "        infile2 = open(ffpath+'/ForceConstants/ForceConstants_Coleman2003.txt', 'r')\n",
    "    elif forcefield == 'Olson1998' or forcefield == 'olson':\n",
    "        infile2 = open(ffpath+'/ForceConstants/ForceConstants_Olson1998.txt', 'r')\n",
    "    else:\n",
    "        infile2 = open(ffpath+'/ForceConstants/ForceConstants_IdealDNA.txt', 'r')\n",
    "    indata2 = infile2.readlines()\n",
    "    indata2 = [i.replace(\"={\",\" \").replace(\", \",\" \").replace(\"}\",\"\").rstrip('\\n').split() for i in indata2]\n",
    "    for i in range(0, len(indata2)):\n",
    "        for j, x in enumerate(indata2[i]):\n",
    "            try:\tindata2[i][j] = float(x)\n",
    "            except ValueError:\tpass\n",
    "    header1 = ['dimer','tilt','roll','twist','shift','slide','rise']\n",
    "    header2 =['dimer',\n",
    "    'TiltTilt','TiltRoll','TiltTwist','TiltShift','TiltSlide','TiltRise',\n",
    "    'RollTilt','RollRoll','RollTwist','RollShift','RollSlide','RollRise',\n",
    "    'TwistTilt','TwistRoll','TwistTwist','TwistShift','TwistSlide','TwistRise',\n",
    "    'ShiftTilt','ShiftRoll','ShiftTwist','ShiftShift','ShiftSlide','ShiftRise',\n",
    "    'SlideTilt','SlideRoll','SlideTwist','SlideShift','SlideSlide','SlideRise',\n",
    "    'RiseTilt','RiseRoll','RiseTwist','RiseShift','RiseSlide','RiseRise']\n",
    "    df1 = pd.DataFrame.from_records(indata1, columns=header1)\n",
    "    df1 = df1.set_index('dimer')\n",
    "    df2 = pd.DataFrame.from_records(indata2, columns=header2)\n",
    "    df2 = df2.set_index('dimer')\n",
    "    del indata1, indata2\n",
    "    return df1, df2\n",
    "\n",
    "def insert_bpstep_seq_circular(opt_par_dataframe):\n",
    "    \"\"\"\n",
    "    From a dataframe with a column of base-pairs, generate the dimer and tetramer for each bp.\n",
    "    Add new dimer and tetramer columns to dataframe.\n",
    "    Note: this is for circular constructions\n",
    "    \"\"\"\n",
    "    bpseq  = opt_par_dataframe['basepair']\n",
    "    for k in range(0, len(bpseq)):\n",
    "        first, second, third, fourth = k-2, k-1, k, k+1 \n",
    "        if k-2 == -2:\n",
    "            first  = (Nseq - 2)\n",
    "            second = (Nseq - 1)\n",
    "        elif k-2 == -1:\n",
    "            first = (Nseq - 1)\n",
    "        elif k == Nseq-1:\n",
    "            fourth = 0\n",
    "        elif k == Nseq:\n",
    "            second = (Nseq-1)\n",
    "            third  = 0\n",
    "            fourth = 1\n",
    "        a = bpseq[first].split('-')[0]\n",
    "        b = bpseq[second].split('-')[0]\n",
    "        c = bpseq[third].split('-')[0]\n",
    "        d = bpseq[fourth].split('-')[0]\n",
    "        dimerstep = \"\".join((b, c))\n",
    "        tetrastep = \"\".join((a, b, c, d))\n",
    "        opt_par_dataframe.at[k, 'dimer'] = dimerstep\n",
    "        opt_par_dataframe.at[k, 'tetramer'] = tetrastep\n",
    "    return opt_par_dataframe\n",
    "\n",
    "def insert_bps_bend(opt_par_dataframe):\n",
    "    \"\"\"\n",
    "    Function that takes the tilt and roll columns from a loaded dataframe and determines the bend angle.\n",
    "    \"\"\"\n",
    "    for k in range(0, len(opt_par_dataframe)):\n",
    "        x = float(opt_par_dataframe.loc[k, 'Tilt'])\n",
    "        y = float(opt_par_dataframe.loc[k, 'Roll'])\n",
    "        opt_par_dataframe.loc[k, 'Bend'] = float(np.sqrt(x**2 + y**2))\n",
    "    return opt_par_dataframe\n",
    "\n",
    "def insert_bps_energy(Nseq, opt_par_dataframe, reststate_par_dataframe, elastic_constants_dataframe):\n",
    "    \"\"\"\n",
    "    Function that determines the energy per base-pair step.\n",
    "    Must have:\n",
    "    - loaded rest state dataframe\n",
    "    - loaded elastic force constant dataframe\n",
    "    - column with dimer and/or tetramer steps\n",
    "    \"\"\"\n",
    "    opt_par_dataframe.loc[0, 'Energy'] = float(0)\n",
    "    \n",
    "    for i in range(1, len(opt_par_dataframe)):\n",
    "        vector = opt_par_dataframe.loc[i]\n",
    "        parvec = reststate_par_dataframe.loc[vector['dimer']].to_numpy()\n",
    "        fcmat  = elastic_constants_dataframe.loc[vector['dimer']].to_numpy().reshape((6,6))\n",
    "        dimvec = vector[['Tilt','Roll','Twist','Shift','Slide','Rise']].to_numpy()\n",
    "        diffvec = dimvec-parvec\n",
    "        energy = 1/2*np.transpose(diffvec).dot( fcmat.dot(diffvec) )\n",
    "        opt_par_dataframe.at[i, 'Energy']=energy\n",
    "        del vector, parvec, fcmat, dimvec, diffvec, energy\n",
    "    \n",
    "    '''\n",
    "    for k in range(1, len(opt_par_dataframe)):\n",
    "        dim = opt_par_dataframe.loc[k, 'dimer']\n",
    "        oshift, oslide, orise, otilt, oroll, otwist = [j for j in opt_par_dataframe.loc[k, 'Shift':'Twist']]\n",
    "        A = np.array([otilt, oroll, otwist, oshift, oslide, orise])\n",
    "        for j in range(0, len(reststate_par_dataframe)):\n",
    "            if reststate_par_dataframe.loc[j, 'dimer'] == dim:\n",
    "                B = np.array([z for z in reststate_par_dataframe.loc[j, 'tilt':'rise']])\n",
    "        for j in range(0, len(elastic_constants_dataframe)):\n",
    "            if elastic_constants_dataframe.loc[j, 'dimer'] == dim:\n",
    "                F = np.array([[z for z in elastic_constants_dataframe.loc[j, 'TiltTilt':'TiltRise']],\n",
    "                              [z for z in elastic_constants_dataframe.loc[j, 'RollTilt':'RollRise']],\n",
    "                              [z for z in elastic_constants_dataframe.loc[j, 'TwistTilt':'TwistRise']],\n",
    "                              [z for z in elastic_constants_dataframe.loc[j, 'ShiftTilt':'ShiftRise']],\n",
    "                              [z for z in elastic_constants_dataframe.loc[j, 'SlideTilt':'SlideRise']],\n",
    "                              [z for z in elastic_constants_dataframe.loc[j, 'RiseTilt':'RiseRise']]])\n",
    "        opt_par_dataframe.loc[k, 'Energy'] = (1/2)*np.trace( (A-B) * F * (A-B) )\n",
    "    '''\n",
    "    return opt_par_dataframe\n",
    "\n",
    "\n",
    "# --- Output new parameter file ---\n",
    "def newfile_bpsdata(Nseq, main_dataframe, outputfilepath, outputname):\n",
    "    \"\"\"\n",
    "    bp, dimer, tetramer, tilt, roll, bend, twist, energy, dcenter, anglecenter, Wmaj, Wmin, ...\n",
    "    \"\"\"\n",
    "    A = main_dataframe\n",
    "    outfile = open(outputfilepath+'/'+outputname+'_bps-data.txt', 'w')\n",
    "    outfile.write(str(Nseq)+'  # base pairs\\n')\n",
    "    if not \"initial\" in str(outputfilepath):\n",
    "        outfile.write(\"{:<4}{:>6}{:>9}{:>10}{:>10}{:>10}{:>10}{:>10}{:>10}{:>10}{:>10}{:>10}\\n\".format(\n",
    "        'bp','dimer','tetramer','Tilt','Roll','Bend','Twist','Energy','distance','theta','W-maj','W-min'\n",
    "        ))\n",
    "        for i in range(0, len(A)):\n",
    "            outfile.write(\"{:<4}{:>6}{:>9}{:>10}{:>10}{:>10}{:>10}{:>10}{:>10}{:>10}{:>10}{:>10}\\n\".format(\n",
    "            A.loc[i, 'basepair'], A.loc[i, 'dimer'], A.loc[i, 'tetramer'],\n",
    "            round(A.loc[i, 'Tilt'],5),round(A.loc[i, 'Roll'],5),round(A.loc[i, 'Bend'],5),round(A.loc[i, 'Twist'],5),round(A.loc[i, 'Energy'], 5),\n",
    "            round(A.loc[i, 'distance'], 5), round(A.loc[i, 'theta'], 5), round(A.loc[i, 'W-maj'], 5), round(A.loc[i, 'W-min'], 5) \n",
    "            ))\n",
    "        outfile.close()\n",
    "    else:\n",
    "        outfile.write(\"{:<4}{:>6}{:>9}{:>10}{:>10}{:>10}{:>10}{:>10}{:>10}{:>10}{:>10}\\n\".format(\n",
    "        'bp','dimer','tetramer','Tilt','Roll','Bend','Twist','distance','theta','W-maj','W-min'\n",
    "        ))\n",
    "        for i in range(0, len(A)):\n",
    "            outfile.write(\"{:<4}{:>6}{:>9}{:>10}{:>10}{:>10}{:>10}{:>10}{:>10}{:>10}{:>10}\\n\".format(\n",
    "            A.loc[i, 'basepair'], A.loc[i, 'dimer'], A.loc[i, 'tetramer'],\n",
    "            round(A.loc[i, 'Tilt'],5),round(A.loc[i, 'Roll'],5),round(A.loc[i, 'Bend'],5),round(A.loc[i, 'Twist'],5),\n",
    "            round(A.loc[i, 'distance'], 5), round(A.loc[i, 'theta'], 5), round(A.loc[i, 'W-maj'], 5), round(A.loc[i, 'W-min'], 5) \n",
    "            ))\n",
    "        outfile.close()\n",
    "    return\n",
    "\n",
    "def load_optdetailed_df(filepath):\n",
    "    infile = open(filepath, 'r')\n",
    "    indata = infile.readlines()\n",
    "    infile.close()\n",
    "    indata = [i.rstrip('\\n').split() for i in indata]\n",
    "    for i in range(0, len(indata)):\n",
    "        for j, x in enumerate(indata[i]):\n",
    "            try:\n",
    "                indata[i][j] = float(x)\n",
    "            except ValueError:\n",
    "                pass\n",
    "    df = pd.DataFrame.from_records(indata[2:], columns=indata[1:2])\n",
    "    df.index = [i for i in range(1, len(df)+1)]\n",
    "    del indata\n",
    "    return df\n",
    "\n",
    "def df_reststate(path):\n",
    "    infile1 = open(path, 'r')\n",
    "    indata1 = infile1.readlines()\n",
    "    infile1.close()            \n",
    "    indata1 = [i.replace(\"={\",\" \").replace(\", \",\" \").replace(\"}\",\"\").rstrip('\\n').split() for i in indata1]\n",
    "    rsdf = pd.DataFrame.from_records(indata1, columns=['dimer','Tilt','Roll','Twist','shift','slide','rise'])\n",
    "    rsdf = rsdf.astype({'Tilt':\"float64\",'Roll':\"float64\",'Twist':\"float64\",'shift':\"float64\",'slide':\"float64\",'rise':\"float64\"})\n",
    "    rsdf = rsdf.set_index('dimer')\n",
    "    return rsdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# '-bps-data.txt' File Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "for filename in os.listdir(pathrf):\n",
    "    lst.append(filename.split('.')[0])\n",
    "lst = sorted(lst)\n",
    "\n",
    "Nseq = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in sorted(lst):\n",
    "    df1, Dcenter = dna_data(pathrf+'/'+filename+'.dat', pathpdb+'/'+filename+'.pdb')\n",
    "    df2 = load_opt_par_dataframe(pathpar+'/'+filename+'.par', Nseq)\n",
    "    \n",
    "    #dfrs, dffc = load_forcefield(ffpath, filename.split('_')[2])\n",
    "    \n",
    "    df1 = circ_major_groove(df1)\n",
    "    df1 = circ_minor_groove(df1)\n",
    "    df2 = insert_bpstep_seq_circular(df2)\n",
    "    df2 = insert_bps_bend(df2)\n",
    "    #df2 = insert_bps_energy(Nseq, df2, dfrs, dffc)\n",
    "    \n",
    "    df3 = df1[['distance','theta','W-maj','W-min']]\n",
    "    df3 = pd.concat([df3, df2[['basepair','dimer','tetramer','Tilt','Roll','Bend','Twist']]], axis=1)\n",
    "    df3 = df3[['basepair','dimer','tetramer','Tilt','Roll','Bend','Twist','distance','theta','W-maj','W-min']]\n",
    "    \n",
    "    df3.loc[len(df3)-1, ['distance', 'theta','W-maj','W-min']]=df3.loc[0, ['distance', 'theta','W-maj','W-min']]\n",
    "    \n",
    "    del df1, df2#, dfrs, dffc\n",
    "    newfile_bpsdata(Nseq, df3, path, filename)\n",
    "    del df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
