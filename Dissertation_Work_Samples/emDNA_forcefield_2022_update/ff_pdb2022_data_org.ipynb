{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e197f514-1829-4b1a-8ff4-7423af2e8236",
   "metadata": {
    "tags": []
   },
   "source": [
    "---------------\n",
    "## Jan 2022- Reorganize the new czapla2022 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7aeda82-8ddc-4d04-a1ce-d57860c8522e",
   "metadata": {
    "tags": []
   },
   "source": [
    "-----------------\n",
    "\n",
    "## Organize bpstep datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e5574b-5318-4e04-87c4-1a42e8533e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import Bio.PDB as PDB\n",
    "from Bio.PDB import MMCIF2Dict\n",
    "\n",
    "path = os.getcwd()\n",
    "datapath = path+'/raw_data_xray-only'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c17cadd-6f0d-4f6c-9c63-d886a90f7526",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### lists and defined functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c73f24-f3be-46c4-8023-bcc3c29c7ea5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "theta_lst = ['tilt','roll','twist','shift','slide','rise']\n",
    "\n",
    "BASES     = ['A','C','G','T']\n",
    "COMP      = {'A':'T', 'T':'A', 'C':'G', 'G':'C','.':'.'}\n",
    "\n",
    "def dna_seq_complement(sequence_string):\n",
    "    COMP = {'A':'T', 'T':'A', 'C':'G', 'G':'C','.':'.'}\n",
    "    STEP = sequence_string[::-1]\n",
    "    STEP = ''.join([COMP[STEP[i]] for i in range(len(STEP))])\n",
    "    return STEP\n",
    "\n",
    "DIMERS    = [b+c for b in ['A','C','G','T'] for c in ['A','C','G','T']]\n",
    "DIMER_LST = ['AT','AC','GC'] + ['AG','GG','GA','AA'] + ['CG','CA','TA']\n",
    "\n",
    "SCDIM = []\n",
    "for DIM in DIMERS:\n",
    "    if COMP[DIM[1]]+COMP[DIM[0]]==DIM:\n",
    "        SCDIM.append(DIM)\n",
    "\n",
    "TET_LST      = [a+b+c+d for a in ['A','C','G','T','.'] for b in BASES for c in BASES for d in ['A','C','G','T','.']]\n",
    "TETRAMERS    = [i for i in TET_LST if '.' not in i]\n",
    "TETRAMER_LST = [\n",
    "    'AAAA','AACA','AAGA','AATA','ACAA','ACGA','AGAA','AGCA','AGGA','ATAA',\n",
    "    'AAAC','AACC','AAGC','AATC','ACAC','ACGC','AGAC','AGCC','AGGC','ATAC',\n",
    "    'AAAG','AACG','AAGG','AATG','ACAG','ACGG','AGAG','AGCG','AGGG','ATAG',\n",
    "    'AAAT','AACT','AAGT','AATT','ACAT','ACGT','AGAT','AGCT','AGGT','ATAT',\n",
    "    'CAAA','CACA','CAGA','CATA','CCAA','CCGA','CGAA','CGCA','CGGA','CTAA',\n",
    "    'CAAC','CACC','CAGC','CCAC','CGAC','CGGC','CAAG','CACG','CAGG','CATG',\n",
    "    'CCAG','CCGG','CGAG','CGCG','CGGG','CTAG','CAAT','CACT','CAGT','CCAT',\n",
    "    'CGAT','CGGT','GAAA','GACA','GAGA','GATA','GCAA','GCGA','GGAA','GGCA',\n",
    "    'GGGA','GTAA','GAAC','GACC','GAGC','GATC','GCAC','GCGC','GGAC','GGCC',\n",
    "    'GGGC','GTAC','GAAG','GACG','GAGG','GATG','GCAG','GCGG','GGAG','GGCG',\n",
    "    'GGGG','GTAG','GAAT','GACT','GAGT','GCAT','GGAT','GGGT','TAAA','TACA',\n",
    "    'TAGA','TATA','TCAA','TCGA','TGAA','TGCA','TGGA','TTAA','TAAC','TACC',\n",
    "    'TAGC','TCAC','TGAC','TGGC','TAAG','TACG','TAGG','TCAG','TGAG','TGGG',\n",
    "    'TAAT','TACT','TAGT','TCAT','TGAT','TGGT'\n",
    "]\n",
    "SCTET        = []\n",
    "for TET in TETRAMERS:\n",
    "    if COMP[TET[3]]+COMP[TET[2]]+COMP[TET[1]]+COMP[TET[0]]==TET and '.' not in TET:\n",
    "        SCTET.append(TET)\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def culling_dictionary(CULL_PAR, DATAFRAME):\n",
    "    return {'tilt':[DATAFRAME.tilt.mean()      - CULL_PAR*DATAFRAME.tilt.std(),     DATAFRAME.tilt.mean()     + CULL_PAR*DATAFRAME.tilt.std()],\n",
    "            'roll':[DATAFRAME.roll.mean()      - CULL_PAR*DATAFRAME.roll.std(),     DATAFRAME.roll.mean()     + CULL_PAR*DATAFRAME.roll.std()], \n",
    "            'twist':[DATAFRAME.twist.mean()    - CULL_PAR*DATAFRAME.twist.std(),    DATAFRAME.twist.mean()    + CULL_PAR*DATAFRAME.twist.std()],\n",
    "            'shift':[DATAFRAME['shift'].mean() - CULL_PAR*DATAFRAME['shift'].std(), DATAFRAME['shift'].mean() + CULL_PAR*DATAFRAME['shift'].std()], \n",
    "            'slide':[DATAFRAME.slide.mean()    - CULL_PAR*DATAFRAME.slide.std(),    DATAFRAME.slide.mean()    + CULL_PAR*DATAFRAME.slide.std()],\n",
    "            'rise':[DATAFRAME.rise.mean()      - CULL_PAR*DATAFRAME.rise.std(),     DATAFRAME.rise.mean()     + CULL_PAR*DATAFRAME.rise.std()]\n",
    "           }\n",
    "\n",
    "\n",
    "def parametric_culling(culling_par, DATAFRAME, CULL_DF):   \n",
    "    # Make dictionary with the sigma limits for each parameter\n",
    "    sigma_check = culling_dictionary(culling_par, DATAFRAME)\n",
    "    # check each entry of dataset to see if all parameters are within their sigma-limit; if not, cull\n",
    "    CULL_IDXS = []\n",
    "    for idx, row in DATAFRAME.iterrows():\n",
    "        VECTOR = DATAFRAME.loc[idx]\n",
    "        VECTOR_CHECK=[]\n",
    "        for theta in ['tilt','roll','twist','shift','slide','rise']:\n",
    "            if sigma_check[theta][0] <= VECTOR[theta].item() <= sigma_check[theta][1]:\n",
    "                VECTOR_CHECK.append(\"pass\")\n",
    "            else:\n",
    "                VECTOR_CHECK.append(\"cull\")\n",
    "                \n",
    "        if len(VECTOR_CHECK)==6 and \"cull\" in VECTOR_CHECK:\n",
    "            CULL_DF  = pd.concat([CULL_DF, DATAFRAME.loc[idx:idx]], ignore_index=True)\n",
    "            CULL_IDXS.append(idx)\n",
    "        del VECTOR, VECTOR_CHECK\n",
    "    CULL_DF  = CULL_DF.reset_index(drop=True)\n",
    "    DATAFRAME = DATAFRAME.drop(index=CULL_IDXS).reset_index(drop=True)\n",
    "    del CULL_IDXS, sigma_check\n",
    "    return DATAFRAME, CULL_DF\n",
    "\n",
    "\n",
    "def culling_cycle(culling_par, CULL_CHECK_DF, STEP_DATAFRAME):\n",
    "    CULL_CYCLE    = 1\n",
    "    CULL_CHECK    = len(CULL_CHECK_DF)\n",
    "    # First culling cycle\n",
    "    STEP_DATAFRAME, CULL_CHECK_DF = parametric_culling(culling_par, STEP_DATAFRAME, CULL_CHECK_DF)\n",
    "    CULL_CYCLE+=1\n",
    "    # Conditionally repeat culling\n",
    "    while (CULL_CYCLE >= 2) and ( len(CULL_CHECK_DF) - CULL_CHECK > 0 ):\n",
    "        CULL_CHECK = len(CULL_CHECK_DF)\n",
    "        STEP_DATAFRAME, CULL_CHECK_DF = parametric_culling(culling_par, STEP_DATAFRAME, CULL_CHECK_DF)\n",
    "        CULL_CYCLE+=1\n",
    "    del CULL_CYCLE, CULL_CHECK\n",
    "    return CULL_CHECK_DF, STEP_DATAFRAME\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f422b9e2-53ca-4f2a-9539-45e21618575d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "----------------------\n",
    "### Load raw dataset, organize and refine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d217184-3358-4346-8be9-f532f94145a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rawdf = pd.read_csv(datapath+'/xray_step_data_feb2022.txt',\n",
    "                    index_col=None, \n",
    "                    header=None,\n",
    "                    sep=',\\s+|\\s+|\\s', \n",
    "                   engine='python')\n",
    "\n",
    "rawdf = rawdf[[12,13,14,15,16,17,30,31]].rename(columns={12:'tilt',13:'roll',14:'twist',15:'shift',16:'slide',17:'rise',30:'pdb_id',31:'step'})\n",
    "\n",
    "rawdf[\"step_dimer\"] = ''\n",
    "rawdf[\"step_tetramer\"] = ''\n",
    "rawdf[\"dimer_neighbors\"] = ''\n",
    "\n",
    "print(len(rawdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8454161-9f69-4c43-8027-f14472be9ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(rawdf)):\n",
    "    \n",
    "    if rawdf.isnull().at[i, \"pdb_id\"]:\n",
    "        rawdf.at[i, 'coding']='n'\n",
    "        \n",
    "    else:\n",
    "        rawdf.at[i, 'coding']='y'\n",
    "        STEP=rawdf.at[i, 'step']\n",
    "        \n",
    "        if len(STEP) == 6:\n",
    "            rawdf.at[i, \"step_dimer\"] = STEP[2:4]\n",
    "            rawdf.at[i, \"step_tetramer\"] = STEP[1:5]\n",
    "            rawdf.at[i, \"dimer_neighbors\"] = STEP[1:2]+'__'+STEP[4:5]\n",
    "        elif len(STEP) == 4:\n",
    "            rawdf.at[i, \"step_dimer\"] = STEP[1:3]\n",
    "            rawdf.at[i, \"step_tetramer\"] = STEP\n",
    "            rawdf.at[i, \"dimer_neighbors\"] = STEP[0:1]+'__'+STEP[3:]\n",
    "        else:\n",
    "            print(\"ERROR AT IDX :\", i)\n",
    "        del STEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccf168a-4114-46de-8fff-14d5aee05c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdf.to_csv(datapath+\"/raw_df_formatted_feb2022\")\n",
    "del rawdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96e3efd-bfb6-44ed-bbfc-ab8e8da01ff9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Process raw dataset and additional refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898a7f39-0d47-4b35-b19a-d9b54095f12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdf = pd.read_csv(datapath+\"/raw_df_formatted_feb2022\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee4307a-2fee-4e2f-ac03-a22ff4248198",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318cf7db-3302-46f0-9909-45613b54b20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len( rawdf[rawdf.pdb_id.isnull()] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3028095-1317-4898-9d2a-91a9127bf449",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdataset = rawdf.copy()\n",
    "\n",
    "rawdf2     = rawdataset.copy().loc[(rawdataset.coding=='y')\n",
    "                                   &(~rawdataset.step_dimer.isin(SCDIM))].reset_index(drop=True)\n",
    "\n",
    "rawdf_coll = rawdataset.copy().loc[(rawdataset.coding=='y')\n",
    "                                   &(rawdataset.step_dimer.isin(SCDIM))].reset_index(drop=True)\n",
    "\n",
    "rawdf_calc = rawdataset.copy().loc[(rawdataset.coding=='n')].reset_index(drop=True)\n",
    "\n",
    "print(len(rawdataset))\n",
    "print()\n",
    "print(len(rawdf2))\n",
    "print(len(rawdf_coll))\n",
    "print(len(rawdf_calc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e456ae3-d851-4a83-a167-28b86202e55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "checker_df = rawdf_calc.copy()\n",
    "checker_df['tilt']  = -1*checker_df['tilt']\n",
    "checker_df['shift'] = -1*checker_df['shift']\n",
    "for i in range(len(checker_df)):\n",
    "    IDX = rawdf_coll.loc[(rawdf_coll['tilt']  == checker_df.at[i,'tilt'])\n",
    "                        &(rawdf_coll['roll']  == checker_df.at[i,'roll'])\n",
    "                        &(rawdf_coll['twist'] == checker_df.at[i,'twist'])\n",
    "                        &(rawdf_coll['shift'] == checker_df.at[i,'shift'])\n",
    "                        &(rawdf_coll['slide'] == checker_df.at[i,'slide'])\n",
    "                        &(rawdf_coll['rise']  == checker_df.at[i,'rise'])\n",
    "                        ].index[0]\n",
    "\n",
    "    rawdf_calc.at[i,'pdb_id']          = rawdf_coll.at[IDX,'pdb_id']\n",
    "    rawdf_calc.at[i,'step_dimer']      = dna_seq_complement(rawdf_coll.at[IDX,'step_dimer'])# COMP[rawdf_coll.at[IDX,'step_dimer'][-1:]] + COMP[rawdf_coll.at[IDX,'step_dimer'][-2:-1]]\n",
    "    rawdf_calc.at[i,'step_tetramer']   = dna_seq_complement(rawdf_coll.at[IDX,'step_tetramer'])# COMP[rawdf_coll.at[IDX,'step_tetramer'][-1:]] + COMP[rawdf_coll.at[IDX,'step_tetramer'][-2:-1]] + COMP[rawdf_coll.at[IDX,'step_tetramer'][-3:-2]] + COMP[rawdf_coll.at[IDX,'step_tetramer'][-4:-3]]\n",
    "    rawdf_calc.at[i,'dimer_neighbors'] = COMP[rawdf_coll.at[IDX,'step_tetramer'][-1:]] + \"__\" + COMP[rawdf_coll.at[IDX,'step_tetramer'][-4:-3]]\n",
    "\n",
    "    \n",
    "compile_df = pd.concat([rawdf2, rawdf_coll, rawdf_calc], axis=0).reset_index(drop=True)\n",
    "\n",
    "print(len(compile_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2305e1e6-3bdc-4623-a981-17ce7a420f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "compile_df[compile_df.coding=='n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66af676b-c9d8-473e-9eb0-3528cf647dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_dataset = compile_df[compile_df.coding=='y'].reset_index(drop=True)\n",
    "mod_dataset = compile_df[compile_df.coding=='n'].reset_index(drop=True)\n",
    "\n",
    "\n",
    "testdf = tab_dataset.copy()\n",
    "\n",
    "IDX_DROP_LIST = []\n",
    "for i in range(len(mod_dataset)):\n",
    "    IDX = testdf.loc[(testdf['tilt']  == -1*mod_dataset.at[i,'tilt'])\n",
    "                        &(testdf['roll']  == mod_dataset.at[i,'roll'])\n",
    "                        &(testdf['twist'] == mod_dataset.at[i,'twist'])\n",
    "                        &(testdf['shift'] == -1*mod_dataset.at[i,'shift'])\n",
    "                        &(testdf['slide'] == mod_dataset.at[i,'slide'])\n",
    "                        &(testdf['rise']  == mod_dataset.at[i,'rise'])\n",
    "                        ].index[0]\n",
    "    IDX_DROP_LIST.append(IDX)\n",
    "    del IDX\n",
    "testdf = testdf.drop([i for i in IDX_DROP_LIST], axis=0).reset_index(drop=True)\n",
    "del IDX_DROP_LIST\n",
    "\n",
    "testdf.coding='n'\n",
    "\n",
    "for i in range(len(testdf)):\n",
    "    DIM = testdf.at[i, 'step_dimer']\n",
    "    TET = testdf.at[i, 'step_tetramer']\n",
    "    \n",
    "    COMP_DIM=dna_seq_complement(DIM)\n",
    "    COMP_TET=dna_seq_complement(TET)\n",
    "    \n",
    "    testdf.at[i, 'step_dimer']    = COMP_DIM\n",
    "    testdf.at[i, 'step_tetramer'] = COMP_TET  \n",
    "    testdf.at[i, 'dimer_neighbors'] = COMP_TET[0:1]+'__'+COMP_TET[3:]\n",
    "    \n",
    "    del DIM, TET, COMP_DIM, COMP_TET\n",
    "\n",
    "testdf['tilt']  = -1*testdf['tilt']\n",
    "testdf['shift'] = -1*testdf['shift']\n",
    "\n",
    "testdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf122bc9-f6cf-4307-ae40-a8899b885354",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_dataset = pd.concat([mod_dataset, testdf], axis=0, ignore_index=True).reset_index(drop=True)\n",
    "del testdf\n",
    "\n",
    "print(len(tab_dataset))\n",
    "print(len(mod_dataset))\n",
    "\n",
    "CHECKDF = pd.concat([tab_dataset, mod_dataset], ignore_index=True).reset_index(drop=True)\n",
    "\n",
    "print(len(CHECKDF))\n",
    "dim2_lst = [a+b for a in ['A','G','C','T'] for b in ['A','G','C','T']]\n",
    "tet2_df  = pd.DataFrame(index=[i for i in dim2_lst],columns=[i[::-1] for i in dim2_lst]).T\n",
    "del dim2_lst\n",
    "\n",
    "for dim1 in tet2_df.index:\n",
    "    for dim2 in tet2_df.columns:\n",
    "        tet2_df.at[dim1, dim2] = len(CHECKDF[CHECKDF.step_tetramer==dim1+dim2])\n",
    "\n",
    "tet2_df = tet2_df.astype(int)\n",
    "del CHECKDF\n",
    "\n",
    "tet_a = tet2_df.to_numpy()\n",
    "tet_b = tet2_df.T.to_numpy()\n",
    "if tet_a.all() == tet_b.all():\n",
    "    print(\"Symmetric\")\n",
    "del tet_a, tet_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45573d6-5e90-4647-948a-3500dd661666",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_dataset=tab_dataset.drop('step', axis=1)\n",
    "mod_dataset=mod_dataset.drop('step', axis=1)\n",
    "\n",
    "print(len(tab_dataset))\n",
    "print(len(mod_dataset))\n",
    "tab_dataset=tab_dataset[~tab_dataset.step_tetramer.str.contains('\\.')].reset_index(drop=True)\n",
    "mod_dataset=mod_dataset[~mod_dataset.step_tetramer.str.contains('\\.')].reset_index(drop=True)\n",
    "print(len(tab_dataset))\n",
    "print(len(mod_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb1d4fc-49ab-4d64-bfd3-f8858aee313c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_dataset[\"DIMER\"]=''\n",
    "mod_dataset[\"TETRAMER\"]=''\n",
    "for i in range(len(mod_dataset)):\n",
    "    if mod_dataset.at[i,\"step_dimer\"] in DIMER_LST:\n",
    "        mod_dataset.at[i,'DIMER']=mod_dataset.at[i,\"step_dimer\"]\n",
    "    else:\n",
    "        mod_dataset.at[i,'DIMER'] = dna_seq_complement(mod_dataset.at[i,'step_dimer'])\n",
    "    \n",
    "    if mod_dataset.at[i,\"step_tetramer\"] in TETRAMER_LST:\n",
    "        mod_dataset.at[i,'TETRAMER']=mod_dataset.at[i,\"step_tetramer\"]\n",
    "    else:\n",
    "        mod_dataset.at[i,'TETRAMER'] = dna_seq_complement(mod_dataset.at[i,'step_tetramer'])\n",
    "\n",
    "tab_dataset[\"DIMER\"]=''\n",
    "tab_dataset[\"TETRAMER\"]=''\n",
    "for i in range(len(tab_dataset)):\n",
    "    if tab_dataset.at[i,\"step_dimer\"] in DIMER_LST:\n",
    "        tab_dataset.at[i,'DIMER']=tab_dataset.at[i,\"step_dimer\"]\n",
    "    else:\n",
    "        tab_dataset.at[i,'DIMER'] = dna_seq_complement(tab_dataset.at[i,'step_dimer'])\n",
    "    \n",
    "    if tab_dataset.at[i,\"step_tetramer\"] in TETRAMER_LST:\n",
    "        tab_dataset.at[i,'TETRAMER']=tab_dataset.at[i,\"step_tetramer\"]\n",
    "    else:\n",
    "        tab_dataset.at[i,'TETRAMER'] = dna_seq_complement(tab_dataset.at[i,'step_tetramer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f174aa53-c228-4ee1-82b1-ab26eecd02a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3dc7d1-dac9-4a30-a269-a9a8f94cf499",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_dataset.to_csv(datapath+\"/czapla-xray-2022_dataset_tabulated\")\n",
    "mod_dataset.to_csv(datapath+\"/czapla-xray-2022_dataset_modified\")\n",
    "\n",
    "CHECKDF = pd.concat([tab_dataset, mod_dataset], ignore_index=True).reset_index(drop=True)\n",
    "CHECKDF.to_csv(datapath+\"/czapla-xray-2022_dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4157403f-37d7-4219-9f77-def26f43db72",
   "metadata": {},
   "outputs": [],
   "source": [
    "del tab_dataset, mod_dataset, CHECKDF, compile_df\n",
    "\n",
    "del rawdataset, rawdf2, rawdf_coll, rawdf_calc, rawdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd61bab-5884-4b98-872b-d5148c7f5a02",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Cull refined dataset and adjust for repeated step-complementary dimers and tetramers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58742433-b95f-48b1-b8c7-7683f4f652a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(datapath+\"/czapla-xray-2022_dataset\", index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35d7dfd-1d8f-4e41-9911-57df10cfc44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = dataset.copy().loc[(~dataset.step_dimer.str.contains('\\.'))\n",
    "                        &(~dataset.dimer_neighbors.str.contains('\\.'))].reset_index(drop=True)\n",
    "\n",
    "df_sig  = pd.DataFrame(columns=DF.columns)\n",
    "df_cull = pd.DataFrame(columns=DF.columns)\n",
    "\n",
    "print('*'*25)\n",
    "print(len(DF))\n",
    "print(len(df_sig))\n",
    "print(len(df_cull))\n",
    "print('*'*25)\n",
    "\n",
    "del DF, df_sig, df_cull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d3003c-bd4a-42ec-869d-4ffb88c45076",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = dataset.copy().loc[(~dataset.step_dimer.str.contains('\\.'))\n",
    "                        &(~dataset.dimer_neighbors.str.contains('\\.'))].reset_index(drop=True)\n",
    "\n",
    "df_sig  = pd.DataFrame(columns=DF.columns)\n",
    "df_cull = pd.DataFrame(columns=DF.columns)\n",
    "\n",
    "print('*'*25)\n",
    "print(len(DF))\n",
    "print(len(df_sig))\n",
    "print(len(df_cull))\n",
    "print('*'*25)\n",
    "\n",
    "for STEP in DIMER_LST:\n",
    "\n",
    "    data_df            = DF.copy().loc[ DF.DIMER==STEP ].reset_index(drop=True)\n",
    "    print(STEP, len(data_df))\n",
    "    culled_df, data_df = culling_cycle(3.0, pd.DataFrame(columns=DF.columns), data_df)\n",
    "    print(\"--- \", len(data_df))\n",
    "    df_sig             = pd.concat([df_sig, data_df], ignore_index=True).reset_index(drop=True)\n",
    "    df_cull            = pd.concat([df_cull, culled_df], ignore_index=True).reset_index(drop=True)\n",
    "    print()\n",
    "    del culled_df, data_df\n",
    "\n",
    "df_sig  = df_sig.reset_index(drop=True)\n",
    "df_cull = df_cull.reset_index(drop=True)\n",
    "\n",
    "print('*'*25)\n",
    "print(len(df_sig))\n",
    "print(len(df_cull))\n",
    "print('*'*25)\n",
    "\n",
    "df_sig.to_csv(\"czapla2022_3sig_dim\")\n",
    "df_cull.to_csv(\"czapla2022_3sig_dim-cull\")\n",
    "\n",
    "del df_sig, df_cull, DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa188cb6-f47e-4790-80ba-54e6e4dc0355",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DF = dataset.copy().loc[(~dataset.step_dimer.str.contains('\\.'))\n",
    "                        &(~dataset.dimer_neighbors.str.contains('\\.'))].reset_index(drop=True)\n",
    "\n",
    "df_sig  = pd.DataFrame(columns=DF.columns)\n",
    "df_cull = pd.DataFrame(columns=DF.columns)\n",
    "\n",
    "print('*'*25)\n",
    "print(len(DF))\n",
    "print(len(df_sig))\n",
    "print(len(df_cull))\n",
    "print('*'*25)\n",
    "\n",
    "for STEP in TETRAMER_LST:\n",
    "\n",
    "    data_df            = DF.copy().loc[ DF.TETRAMER==STEP ].reset_index(drop=True)\n",
    "    print(STEP, len(data_df))\n",
    "    culled_df, data_df = culling_cycle(3.0, pd.DataFrame(columns=DF.columns), data_df)\n",
    "    print(\"--- \", len(data_df))\n",
    "    df_sig             = pd.concat([df_sig, data_df], ignore_index=True).reset_index(drop=True)\n",
    "    df_cull            = pd.concat([df_cull, culled_df], ignore_index=True).reset_index(drop=True)\n",
    "    print()\n",
    "    del culled_df, data_df\n",
    "\n",
    "df_sig  = df_sig.reset_index(drop=True)\n",
    "df_cull = df_cull.reset_index(drop=True)\n",
    "\n",
    "print('*'*25)\n",
    "print(len(df_sig))\n",
    "print(len(df_cull))\n",
    "print('*'*25)\n",
    "\n",
    "df_sig.to_csv(\"czapla2022_3sig_tet\")\n",
    "df_cull.to_csv(\"czapla2022_3sig_tet-cull\")\n",
    "\n",
    "del df_sig, df_cull, DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62144920-89a4-4bc0-8bd9-3a03c2753993",
   "metadata": {},
   "outputs": [],
   "source": [
    "del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b74a70e-3cdd-47ba-aa3d-af95201586e8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "--------------------------\n",
    "### Make \"modified\" data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c6d413-d53b-4857-89ed-bed0de013f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"czapla2022_3sig_tet\", index_col=0)\n",
    "\n",
    "tab_dataset = dataset[dataset.coding=='y'].reset_index(drop=True)\n",
    "mod_dataset = dataset[dataset.coding=='n'].reset_index(drop=True)\n",
    "\n",
    "print(len(dataset))\n",
    "print(len(tab_dataset))\n",
    "print(len(mod_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f334bb-167b-43fd-bf1c-901eb9254f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_ind_lst=[]\n",
    "for i in range(len(mod_dataset)):\n",
    "    try:\n",
    "        IDX = tab_dataset.loc[(tab_dataset['tilt']  == -1*mod_dataset.at[i,'tilt'])\n",
    "                                &(tab_dataset['roll']  == mod_dataset.at[i,'roll'])\n",
    "                                &(tab_dataset['twist'] == mod_dataset.at[i,'twist'])\n",
    "                                &(tab_dataset['shift'] == -1*mod_dataset.at[i,'shift'])\n",
    "                                &(tab_dataset['slide'] == mod_dataset.at[i,'slide'])\n",
    "                                &(tab_dataset['rise']  == mod_dataset.at[i,'rise'])\n",
    "                                ].index[0]\n",
    "\n",
    "        dup_ind_lst.append(IDX)\n",
    "        del IDX\n",
    "    except ValueError:\n",
    "        continue\n",
    "print(len(dup_ind_lst))\n",
    "    \n",
    "del dup_ind_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f640583c-de31-4887-b1ec-9eb6d251344c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_dataset.to_csv(\"czapla2022_3sig_tet_tab\")\n",
    "mod_dataset.to_csv(\"czapla2022_3sig_tet_mod\")\n",
    "\n",
    "del tab_dataset, mod_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8b0233-2952-4699-952c-2b1daf6af960",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1d88d7-4e03-4d1a-bcb3-16e0b8be5825",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9a9f9a8-5447-4b3e-b8ea-f2afc4928a38",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "\n",
    "----------\n",
    "## Add pdb-specific details to datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2f45f6-063e-44cd-835a-be3fca92df29",
   "metadata": {},
   "outputs": [],
   "source": [
    "detdf = pd.read_csv(\"czapla2022_pdbid_data\", index_col=0)\n",
    "\n",
    "original_dataset = pd.read_csv(datapath+\"/czapla-xray-2022_dataset\", index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a1e575-f178-4136-9233-ea22c4f41843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a yearly dataset\n",
    "yrds = original_dataset.copy()\n",
    "for i in range(len(yrds)):\n",
    "    yrds.at[i, 'year']=detdf.loc[yrds.at[i, 'pdb_id']]['deposit_year']\n",
    "yrds.year=yrds.year.astype(int)\n",
    "yrds.to_csv(\"czapla2022_yearly_dataset\")\n",
    "del yrds\n",
    "\n",
    "#make a resolution dataset\n",
    "resds = original_dataset.copy()\n",
    "for i in range(len(resds)):\n",
    "    resds.at[i, 'resolution']=detdf.loc[resds.at[i, 'pdb_id']]['resolution']\n",
    "    \n",
    "resds.to_csv(\"czapla2022_res_dataset\")\n",
    "del resds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf56ffa-b3cf-428d-a1d8-96f4fe0efc41",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Cull based on pdb-specific datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ecfd3b-f49b-4111-99a7-6a01596119a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"czapla2022_res_dataset\", index_col=0)\n",
    "\n",
    "for RES in [1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 6.0, 10.0]:\n",
    "    df_sig  = pd.DataFrame(columns=dataset.columns)\n",
    "    df_cull = pd.DataFrame(columns=dataset.columns)\n",
    "    \n",
    "    DF = dataset.copy().loc[dataset.resolution<=RES].reset_index(drop=True) \n",
    "    DF = DF.loc[ ~DF.step_tetramer.str.contains('\\.') ].reset_index(drop=True)\n",
    "    \n",
    "    print(RES)\n",
    "    print(len(DF))\n",
    "    \n",
    "    for STEP in TETRAMER_LST:\n",
    "\n",
    "        data_df            = DF.copy().loc[ DF.TETRAMER==STEP ].reset_index(drop=True)\n",
    "        culled_df, data_df = culling_cycle(3.0, pd.DataFrame(columns=DF.columns), data_df)\n",
    "        df_sig             = pd.concat([df_sig, data_df], ignore_index=True).reset_index(drop=True)\n",
    "        df_cull            = pd.concat([df_cull, culled_df], ignore_index=True).reset_index(drop=True)\n",
    "        del culled_df, data_df\n",
    "    print(len(df_sig))\n",
    "    \n",
    "    df_sig  = df_sig.reset_index(drop=True)   \n",
    "    df_sig.to_csv(\"czapla2022_pdb-series_res-series_\"+str(int(RES*10)).zfill(3)+\"_data\")\n",
    "    \n",
    "    df_cull = df_cull.reset_index(drop=True)\n",
    "    df_cull.to_csv(\"czapla2022_pdb-series_res-series_\"+str(int(RES*10)).zfill(3)+\"_culled\")\n",
    "    print('-'*5)\n",
    "    del DF\n",
    "    del df_sig, df_cull\n",
    "    \n",
    "del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bda6ef-c438-4daa-9e36-9f787ddb3fde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"czapla2022_yearly_dataset\", index_col=0)\n",
    "\n",
    "if 'TETRAMER' not in dataset.columns:\n",
    "    for i in range(len(dataset)):\n",
    "        STEP=dataset.at[i, 'step_tetramer']\n",
    "        if STEP not in TETRAMER_LST:\n",
    "            STEP=dna_seq_complement(STEP)\n",
    "        dataset.at[i, 'DIMER']=STEP[1:3]\n",
    "        dataset.at[i, 'TETRAMER']=STEP\n",
    "        del STEP\n",
    "\n",
    "for YEAR in [2000, 2002, 2004, 2006, 2008, 2010, 2012, 2014, 2016, 2018, 2020, 2022]:\n",
    "    \n",
    "    df_sig  = pd.DataFrame(columns=dataset.columns)\n",
    "    df_cull = pd.DataFrame(columns=dataset.columns)\n",
    "    \n",
    "    DF = dataset.copy().loc[dataset.year<=YEAR].reset_index(drop=True) \n",
    "    DF = DF.loc[ ~DF.step_tetramer.str.contains('\\.') ].reset_index(drop=True)\n",
    "    \n",
    "    print(YEAR)\n",
    "    print(len(DF))\n",
    "    \n",
    "    for STEP in TETRAMER_LST:\n",
    "        data_df            = DF.copy().loc[ DF.TETRAMER==STEP ].reset_index(drop=True)\n",
    "        culled_df, data_df = culling_cycle(3.0, pd.DataFrame(columns=DF.columns), data_df)\n",
    "        df_sig             = pd.concat([df_sig, data_df], ignore_index=True).reset_index(drop=True)\n",
    "        df_cull            = pd.concat([df_cull, culled_df], ignore_index=True).reset_index(drop=True)\n",
    "        del culled_df, data_df\n",
    "    print(len(df_sig))\n",
    "    df_sig  = df_sig.reset_index(drop=True)   \n",
    "    df_sig.to_csv(\"czapla2022_pdb-series_year-series_\"+str(YEAR)+\"_data\")\n",
    "    print('-'*5)\n",
    "    df_cull = df_cull.reset_index(drop=True)\n",
    "    df_cull.to_csv(\"czapla2022_pdb-series_year-series_\"+str(YEAR)+\"_culled\")\n",
    "    \n",
    "    del DF\n",
    "    del df_sig, df_cull\n",
    "    \n",
    "del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5394e1-49d5-4880-8630-80a3e2cd3f30",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### modified pdb-series datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811941d1-a53b-4912-a454-e18c2e1ed702",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_path = path+'/pdb_res-series-data'\n",
    "for RES in [1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 6.0, 10.0]:\n",
    "    dataset = pd.read_csv(set_path+\"/czapla2022_pdb-series_res-series_\"+str(int(RES*10)).zfill(3)+\"_data\", index_col=0)\n",
    "    tab_dataset = dataset[dataset.coding=='y'].reset_index(drop=True)\n",
    "    mod_dataset = dataset[dataset.coding=='n'].reset_index(drop=True)\n",
    "    tab_dataset.to_csv(set_path+\"/czapla2022_pdb-series_res-series_\"+str(int(RES*10)).zfill(3)+\"_data_tab\")\n",
    "    mod_dataset.to_csv(set_path+\"/czapla2022_pdb-series_res-series_\"+str(int(RES*10)).zfill(3)+\"_data_mod\")\n",
    "    del tab_dataset, mod_dataset, dataset\n",
    "del set_path\n",
    "\n",
    "\n",
    "set_path = path+'/pdb_time-series-data'\n",
    "for YEAR in [2000, 2002, 2004, 2006, 2008, 2010, 2012, 2014, 2016, 2018, 2020, 2022]:\n",
    "    dataset = pd.read_csv(set_path+\"/czapla2022_pdb-series_year-series_\"+str(YEAR)+\"_data\", index_col=0)\n",
    "    tab_dataset = dataset[dataset.coding=='y'].reset_index(drop=True)\n",
    "    mod_dataset = dataset[dataset.coding=='n'].reset_index(drop=True)\n",
    "    tab_dataset.to_csv(set_path+\"/czapla2022_pdb-series_year-series_\"+str(YEAR)+\"_data_tab\")\n",
    "    mod_dataset.to_csv(set_path+\"/czapla2022_pdb-series_year-series_\"+str(YEAR)+\"_data_mod\")\n",
    "    del tab_dataset, mod_dataset, dataset\n",
    "del set_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6614b4ad-b7a5-4084-b8f9-f648b4e3c5a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45b2b0d0-9f98-463b-8f12-93d04907d313",
   "metadata": {},
   "source": [
    "## Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb1b6de-cb75-4200-8754-3e4dbbb732b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf = pd.read_csv(\"czapla2022_3sig_tet\", index_col=0)\n",
    "testdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a323ce3e-8481-4144-b346-be73444f477f",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf[(testdf.step_dimer=='TT')&(testdf.pdb_id==\"3FYL\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1884de-ed33-4730-a338-8e9b407374dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
